"""
Streamlit EDA App for Pasture Biomass Prediction
"""

from datetime import datetime
from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import seaborn as sns
import streamlit as st
from PIL import Image
from plotly.subplots import make_subplots

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ç‰§è‰ãƒã‚¤ã‚ªãƒã‚¹äºˆæ¸¬ EDA",
    page_icon="ğŸŒ±",
    layout="wide",
    initial_sidebar_state="expanded",
)


# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
@st.cache_data
def load_data():
    """ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥"""
    train_df = pd.read_csv("/kaggle/input/csiro-biomass/train.csv")
    test_df = pd.read_csv("/kaggle/input/csiro-biomass/test.csv")
    sample_submission = pd.read_csv("/kaggle/input/csiro-biomass/sample_submission.csv")

    # æ—¥ä»˜ã‚’ datetime ã«å¤‰æ›
    train_df["Sampling_Date"] = pd.to_datetime(train_df["Sampling_Date"])

    # æœˆã€å¹´ã€å­£ç¯€ã‚’è¿½åŠ 
    train_df["Year"] = train_df["Sampling_Date"].dt.year
    train_df["Month"] = train_df["Sampling_Date"].dt.month
    train_df["Season"] = train_df["Month"].apply(
        lambda x: "Spring"
        if x in [9, 10, 11]
        else "Summer"
        if x in [12, 1, 2]
        else "Autumn"
        if x in [3, 4, 5]
        else "Winter"
    )

    return train_df, test_df, sample_submission


# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
train_df, test_df, sample_submission = load_data()

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
st.sidebar.title("ğŸŒ± Navigation")
page = st.sidebar.radio(
    "ãƒšãƒ¼ã‚¸ã‚’é¸æŠ",
    [
        "ğŸ“Š Overview",
        "ğŸ“ˆ Target Analysis",
        "ğŸ—ºï¸ Geographical Analysis",
        "ğŸ“… Temporal Analysis",
        "ğŸŒ¿ Species Analysis",
        "ğŸ“ Feature Analysis",
        "ğŸ–¼ï¸ Image Viewer",
        "ğŸ”— Correlation Analysis",
    ],
)

# ã‚¿ã‚¤ãƒˆãƒ«
st.title("ğŸŒ± ç‰§è‰ãƒã‚¤ã‚ªãƒã‚¹äºˆæ¸¬ - æ¢ç´¢çš„ãƒ‡ãƒ¼ã‚¿åˆ†æ")
st.markdown("---")

# ================== Overview ==================
if page == "ğŸ“Š Overview":
    st.header("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ¦‚è¦")

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("è¨“ç·´ã‚µãƒ³ãƒ—ãƒ«æ•°", len(train_df))
        st.metric("ãƒ¦ãƒ‹ãƒ¼ã‚¯ç”»åƒæ•°", train_df["image_path"].nunique())
    with col2:
        st.metric("ãƒ†ã‚¹ãƒˆã‚µãƒ³ãƒ—ãƒ«æ•°", len(test_df))
        st.metric("ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç¨®é¡æ•°", train_df["target_name"].nunique())
    with col3:
        st.metric("å·ã®æ•°", train_df["State"].nunique())
        st.metric("ç¨®ã®ç¨®é¡æ•°", train_df["Species"].nunique())

    st.markdown("---")

    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª¬æ˜
    st.subheader("ğŸ“ ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³æ¦‚è¦")
    st.markdown("""
    ã“ã®ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ã§ã¯ã€ç‰§è‰ã®ç”»åƒã‹ã‚‰ä»¥ä¸‹ã®5ã¤ã®ãƒã‚¤ã‚ªãƒã‚¹æˆåˆ†ã‚’äºˆæ¸¬ã—ã¾ã™:
    
    1. **Dry_Green_g**: ä¹¾ç‡¥ç·‘è‰²æ¤ç”Ÿï¼ˆã‚¯ãƒ­ãƒ¼ãƒãƒ¼ã‚’é™¤ãï¼‰
    2. **Dry_Dead_g**: ä¹¾ç‡¥æ­»ç‰©è³ª
    3. **Dry_Clover_g**: ä¹¾ç‡¥ã‚¯ãƒ­ãƒ¼ãƒãƒ¼ãƒã‚¤ã‚ªãƒã‚¹
    4. **GDM_g**: ç·‘è‰²ä¹¾ç‰©
    5. **Dry_Total_g**: ç·ä¹¾ç‡¥ãƒã‚¤ã‚ªãƒã‚¹
    """)

    st.markdown("---")

    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
    st.subheader("ğŸ” è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«")
    st.dataframe(train_df.head(20), use_container_width=True)

    # ãƒ‡ãƒ¼ã‚¿å‹ã¨æ¬ æå€¤
    st.markdown("---")
    col1, col2 = st.columns(2)

    with col1:
        st.subheader("ğŸ“‹ ã‚«ãƒ©ãƒ æƒ…å ±")
        info_df = pd.DataFrame(
            {
                "Column": train_df.columns,
                "Type": train_df.dtypes.astype(str),
                "Non-Null Count": train_df.count(),
                "Null Count": train_df.isnull().sum(),
            }
        )
        st.dataframe(info_df, use_container_width=True)

    with col2:
        st.subheader("ğŸ“Š åŸºæœ¬çµ±è¨ˆé‡")
        st.dataframe(train_df.describe(), use_container_width=True)

# ================== Target Analysis ==================
elif page == "ğŸ“ˆ Target Analysis":
    st.header("ğŸ“ˆ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°åˆ†æ")

    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã”ã¨ã®çµ±è¨ˆ
    st.subheader("ğŸ¯ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ¥çµ±è¨ˆ")
    target_stats = (
        train_df.groupby("target_name")["target"]
        .agg(["count", "mean", "std", "min", "max", "median"])
        .round(2)
    )
    st.dataframe(target_stats, use_container_width=True)

    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®åˆ†å¸ƒ
    st.markdown("---")
    st.subheader("ğŸ“Š ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå€¤ã®åˆ†å¸ƒ")

    target_names = train_df["target_name"].unique()

    # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
    fig = make_subplots(
        rows=2,
        cols=3,
        subplot_titles=list(target_names),
        vertical_spacing=0.15,
        horizontal_spacing=0.1,
    )

    for idx, target in enumerate(target_names):
        row = idx // 3 + 1
        col = idx % 3 + 1

        data = train_df[train_df["target_name"] == target]["target"]
        fig.add_trace(go.Histogram(x=data, name=target, nbinsx=50), row=row, col=col)

    fig.update_layout(
        height=600, showlegend=False, title_text="ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå€¤ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ "
    )
    st.plotly_chart(fig, use_container_width=True)

    # Box plot
    st.markdown("---")
    st.subheader("ğŸ“¦ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå€¤ã®ç®±ã²ã’å›³")
    fig = px.box(
        train_df,
        x="target_name",
        y="target",
        color="target_name",
        title="ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ¥ã®åˆ†å¸ƒ",
    )
    fig.update_layout(height=500)
    st.plotly_chart(fig, use_container_width=True)

    # Log scale
    st.markdown("---")
    st.subheader("ğŸ“Š å¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ã§ã®åˆ†å¸ƒ")
    train_df_nonzero = train_df[train_df["target"] > 0].copy()
    train_df_nonzero["log_target"] = np.log1p(train_df_nonzero["target"])

    fig = px.histogram(
        train_df_nonzero,
        x="log_target",
        color="target_name",
        facet_col="target_name",
        facet_col_wrap=3,
        title="log(target+1)ã®åˆ†å¸ƒ",
    )
    fig.update_layout(height=600)
    st.plotly_chart(fig, use_container_width=True)

    # ã‚¼ãƒ­å€¤ã®å‰²åˆ
    st.markdown("---")
    st.subheader("ğŸ”¢ ã‚¼ãƒ­å€¤ã®å‰²åˆ")
    zero_ratio = (
        train_df.groupby("target_name")
        .apply(lambda x: (x["target"] == 0).sum() / len(x) * 100)
        .round(2)
    )

    fig = px.bar(
        x=zero_ratio.index,
        y=zero_ratio.values,
        labels={"x": "Target Name", "y": "Zero Ratio (%)"},
        title="ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ¥ã‚¼ãƒ­å€¤ã®å‰²åˆ",
    )
    st.plotly_chart(fig, use_container_width=True)

# ================== Geographical Analysis ==================
elif page == "ğŸ—ºï¸ Geographical Analysis":
    st.header("ğŸ—ºï¸ åœ°ç†çš„åˆ†æ")

    # ç”»åƒã”ã¨ã«é›†ç´„ï¼ˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆãŒ5è¡Œã«åˆ†ã‹ã‚Œã¦ã„ã‚‹ã®ã§1è¡Œã«ã¾ã¨ã‚ã‚‹ï¼‰
    image_df = train_df.drop_duplicates(subset=["image_path"]).copy()

    # å·åˆ¥ã®ã‚µãƒ³ãƒ—ãƒ«æ•°
    st.subheader("ğŸ“ å·åˆ¥ã‚µãƒ³ãƒ—ãƒ«æ•°")
    col1, col2 = st.columns(2)

    with col1:
        state_counts = image_df["State"].value_counts()
        st.dataframe(state_counts.to_frame("Count"), use_container_width=True)

    with col2:
        fig = px.pie(
            values=state_counts.values,
            names=state_counts.index,
            title="å·åˆ¥ã‚µãƒ³ãƒ—ãƒ«åˆ†å¸ƒ",
        )
        st.plotly_chart(fig, use_container_width=True)

    # å·åˆ¥ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ†å¸ƒ
    st.markdown("---")
    st.subheader("ğŸ“Š å·åˆ¥ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå€¤ã®åˆ†å¸ƒ")

    fig = px.box(
        train_df,
        x="State",
        y="target",
        color="target_name",
        title="å·åˆ¥ãƒ»ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ¥ã®å€¤ã®åˆ†å¸ƒ",
    )
    fig.update_layout(height=500)
    st.plotly_chart(fig, use_container_width=True)

    # å·åˆ¥ã®å¹³å‡å€¤
    st.markdown("---")
    st.subheader("ğŸ“ˆ å·åˆ¥ãƒ»ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ¥å¹³å‡å€¤")

    state_target_mean = train_df.pivot_table(
        values="target", index="State", columns="target_name", aggfunc="mean"
    ).round(2)

    fig = px.imshow(
        state_target_mean.T,
        labels=dict(x="State", y="Target Name", color="Mean Value"),
        title="å·åˆ¥ãƒ»ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ¥å¹³å‡å€¤ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—",
        aspect="auto",
        color_continuous_scale="Viridis",
    )
    st.plotly_chart(fig, use_container_width=True)
    st.dataframe(state_target_mean, use_container_width=True)

# ================== Temporal Analysis ==================
elif page == "ğŸ“… Temporal Analysis":
    st.header("ğŸ“… æ™‚ç³»åˆ—åˆ†æ")

    # å¹´åˆ¥ã‚µãƒ³ãƒ—ãƒ«æ•°
    st.subheader("ğŸ“† å¹´åˆ¥ã‚µãƒ³ãƒ—ãƒ«æ•°")
    col1, col2 = st.columns(2)

    image_df = train_df.drop_duplicates(subset=["image_path"]).copy()

    with col1:
        year_counts = image_df["Year"].value_counts().sort_index()
        st.dataframe(year_counts.to_frame("Count"), use_container_width=True)

    with col2:
        fig = px.bar(
            x=year_counts.index,
            y=year_counts.values,
            labels={"x": "Year", "y": "Count"},
            title="å¹´åˆ¥ã‚µãƒ³ãƒ—ãƒ«åˆ†å¸ƒ",
        )
        st.plotly_chart(fig, use_container_width=True)

    # æœˆåˆ¥ã‚µãƒ³ãƒ—ãƒ«æ•°
    st.markdown("---")
    st.subheader("ğŸ“… æœˆåˆ¥ã‚µãƒ³ãƒ—ãƒ«æ•°")
    col1, col2 = st.columns(2)

    with col1:
        month_counts = image_df["Month"].value_counts().sort_index()
        st.dataframe(month_counts.to_frame("Count"), use_container_width=True)

    with col2:
        fig = px.bar(
            x=month_counts.index,
            y=month_counts.values,
            labels={"x": "Month", "y": "Count"},
            title="æœˆåˆ¥ã‚µãƒ³ãƒ—ãƒ«åˆ†å¸ƒ",
        )
        st.plotly_chart(fig, use_container_width=True)

    # å­£ç¯€åˆ¥åˆ†æ
    st.markdown("---")
    st.subheader("ğŸŒ¸ å­£ç¯€åˆ¥åˆ†æ")

    season_counts = image_df["Season"].value_counts()
    col1, col2 = st.columns(2)

    with col1:
        st.dataframe(season_counts.to_frame("Count"), use_container_width=True)

    with col2:
        fig = px.pie(
            values=season_counts.values,
            names=season_counts.index,
            title="å­£ç¯€åˆ¥ã‚µãƒ³ãƒ—ãƒ«åˆ†å¸ƒ",
        )
        st.plotly_chart(fig, use_container_width=True)

    # æ™‚ç³»åˆ—ã§ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå€¤æ¨ç§»
    st.markdown("---")
    st.subheader("ğŸ“ˆ æ™‚ç³»åˆ—ã§ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå€¤æ¨ç§»")

    # æœˆåˆ¥å¹³å‡
    monthly_target = (
        train_df.groupby(["Month", "target_name"])["target"].mean().reset_index()
    )
    fig = px.line(
        monthly_target,
        x="Month",
        y="target",
        color="target_name",
        title="æœˆåˆ¥ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¹³å‡å€¤ã®æ¨ç§»",
        markers=True,
    )
    st.plotly_chart(fig, use_container_width=True)

    # å­£ç¯€åˆ¥ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ†å¸ƒ
    st.markdown("---")
    st.subheader("ğŸ‚ å­£ç¯€åˆ¥ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ†å¸ƒ")
    fig = px.box(
        train_df,
        x="Season",
        y="target",
        color="target_name",
        title="å­£ç¯€åˆ¥ãƒ»ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ¥ã®å€¤ã®åˆ†å¸ƒ",
    )
    fig.update_layout(height=500)
    st.plotly_chart(fig, use_container_width=True)

# ================== Species Analysis ==================
elif page == "ğŸŒ¿ Species Analysis":
    st.header("ğŸŒ¿ ç¨®ã®åˆ†æ")

    image_df = train_df.drop_duplicates(subset=["image_path"]).copy()

    # ç¨®åˆ¥ã‚µãƒ³ãƒ—ãƒ«æ•°
    st.subheader("ğŸŒ± ç¨®åˆ¥ã‚µãƒ³ãƒ—ãƒ«æ•°ï¼ˆTop 20ï¼‰")
    species_counts = image_df["Species"].value_counts().head(20)

    fig = px.bar(
        x=species_counts.values,
        y=species_counts.index,
        orientation="h",
        labels={"x": "Count", "y": "Species"},
        title="ç¨®åˆ¥ã‚µãƒ³ãƒ—ãƒ«æ•° Top 20",
    )
    fig.update_layout(height=600)
    st.plotly_chart(fig, use_container_width=True)

    # ç¨®åˆ¥ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ†å¸ƒï¼ˆTop 10ç¨®ï¼‰
    st.markdown("---")
    st.subheader("ğŸ“Š ä¸»è¦ç¨®åˆ¥ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå€¤ã®åˆ†å¸ƒ")

    top_species = species_counts.head(10).index.tolist()
    train_df_top = train_df[train_df["Species"].isin(top_species)]

    fig = px.box(
        train_df_top,
        x="Species",
        y="target",
        color="target_name",
        title="ä¸»è¦ç¨®åˆ¥ãƒ»ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ¥ã®å€¤ã®åˆ†å¸ƒ",
    )
    fig.update_layout(height=600)
    fig.update_xaxes(tickangle=45)
    st.plotly_chart(fig, use_container_width=True)

    # ç¨®åˆ¥ã®å¹³å‡å€¤æ¯”è¼ƒ
    st.markdown("---")
    st.subheader("ğŸ“ˆ ä¸»è¦ç¨®åˆ¥ãƒ»ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ¥å¹³å‡å€¤")

    species_target_mean = train_df_top.pivot_table(
        values="target", index="Species", columns="target_name", aggfunc="mean"
    ).round(2)

    st.dataframe(species_target_mean, use_container_width=True)

    # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
    fig = px.imshow(
        species_target_mean.T,
        labels=dict(x="Species", y="Target Name", color="Mean Value"),
        title="ç¨®åˆ¥ãƒ»ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ¥å¹³å‡å€¤ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—",
        aspect="auto",
        color_continuous_scale="Viridis",
    )
    st.plotly_chart(fig, use_container_width=True)

    # ç¨®ã®å¤šæ§˜æ€§
    st.markdown("---")
    st.subheader("ğŸ”¢ ç¨®ã®å¤šæ§˜æ€§")

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ãƒ¦ãƒ‹ãƒ¼ã‚¯ç¨®æ•°", image_df["Species"].nunique())
    with col2:
        st.metric("æœ€å¤šç¨®ã‚µãƒ³ãƒ—ãƒ«æ•°", species_counts.iloc[0])
    with col3:
        st.metric("æœ€å°‘ç¨®ã‚µãƒ³ãƒ—ãƒ«æ•°", species_counts.iloc[-1])

# ================== Feature Analysis ==================
elif page == "ğŸ“ Feature Analysis":
    st.header("ğŸ“ ç‰¹å¾´é‡åˆ†æ")

    # NDVIåˆ†æ
    st.subheader("ğŸŒ¿ NDVI (Pre_GSHH_NDVI) åˆ†æ")

    col1, col2 = st.columns(2)
    with col1:
        st.write("**åŸºæœ¬çµ±è¨ˆé‡**")
        st.dataframe(train_df["Pre_GSHH_NDVI"].describe(), use_container_width=True)

    with col2:
        fig = px.histogram(
            train_df.drop_duplicates(subset=["image_path"]),
            x="Pre_GSHH_NDVI",
            nbins=50,
            title="NDVIåˆ†å¸ƒ",
        )
        st.plotly_chart(fig, use_container_width=True)

    # NDVIã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®é–¢ä¿‚
    st.markdown("---")
    st.subheader("ğŸ“Š NDVIã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå€¤ã®é–¢ä¿‚")

    fig = px.scatter(
        train_df,
        x="Pre_GSHH_NDVI",
        y="target",
        color="target_name",
        facet_col="target_name",
        facet_col_wrap=3,
        title="NDVIã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå€¤ã®æ•£å¸ƒå›³",
        opacity=0.5,
    )
    fig.update_layout(height=600)
    st.plotly_chart(fig, use_container_width=True)

    # é«˜ã•åˆ†æ
    st.markdown("---")
    st.subheader("ğŸ“ ç‰§è‰ã®é«˜ã• (Height_Ave_cm) åˆ†æ")

    col1, col2 = st.columns(2)
    with col1:
        st.write("**åŸºæœ¬çµ±è¨ˆé‡**")
        st.dataframe(train_df["Height_Ave_cm"].describe(), use_container_width=True)

    with col2:
        fig = px.histogram(
            train_df.drop_duplicates(subset=["image_path"]),
            x="Height_Ave_cm",
            nbins=50,
            title="é«˜ã•åˆ†å¸ƒ",
        )
        st.plotly_chart(fig, use_container_width=True)

    # é«˜ã•ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®é–¢ä¿‚
    st.markdown("---")
    st.subheader("ğŸ“Š é«˜ã•ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå€¤ã®é–¢ä¿‚")

    fig = px.scatter(
        train_df,
        x="Height_Ave_cm",
        y="target",
        color="target_name",
        facet_col="target_name",
        facet_col_wrap=3,
        title="é«˜ã•ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå€¤ã®æ•£å¸ƒå›³",
        opacity=0.5,
    )
    fig.update_layout(height=600)
    st.plotly_chart(fig, use_container_width=True)

    # NDVIã¨é«˜ã•ã®é–¢ä¿‚
    st.markdown("---")
    st.subheader("ğŸ”— NDVIã¨é«˜ã•ã®é–¢ä¿‚")

    image_df = train_df.drop_duplicates(subset=["image_path"]).copy()
    fig = px.scatter(
        image_df,
        x="Pre_GSHH_NDVI",
        y="Height_Ave_cm",
        color="State",
        title="NDVIã¨é«˜ã•ã®æ•£å¸ƒå›³",
        opacity=0.6,
    )
    st.plotly_chart(fig, use_container_width=True)

# ================== Image Viewer ==================
elif page == "ğŸ–¼ï¸ Image Viewer":
    st.header("ğŸ–¼ï¸ ç”»åƒãƒ“ãƒ¥ãƒ¼ã‚¢")

    image_df = train_df.drop_duplicates(subset=["image_path"]).copy()

    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    st.sidebar.subheader("ğŸ” ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼")

    selected_state = st.sidebar.selectbox(
        "å·ã‚’é¸æŠ", ["All"] + sorted(image_df["State"].unique().tolist())
    )
    selected_species = st.sidebar.selectbox(
        "ç¨®ã‚’é¸æŠ", ["All"] + sorted(image_df["Species"].unique().tolist())[:20]
    )

    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    filtered_df = image_df.copy()
    if selected_state != "All":
        filtered_df = filtered_df[filtered_df["State"] == selected_state]
    if selected_species != "All":
        filtered_df = filtered_df[filtered_df["Species"] == selected_species]

    st.write(f"ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¾Œã®ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(filtered_df)}")

    # ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒ«ã‚’è¡¨ç¤º
    if len(filtered_df) > 0:
        n_images = st.slider("è¡¨ç¤ºç”»åƒæ•°", 1, min(20, len(filtered_df)), 6)

        sample_images = filtered_df.sample(n=min(n_images, len(filtered_df)))

        cols_per_row = 3
        for i in range(0, len(sample_images), cols_per_row):
            cols = st.columns(cols_per_row)

            for j, (idx, row) in enumerate(
                list(sample_images.iloc[i : i + cols_per_row].iterrows())
            ):
                with cols[j]:
                    image_path = Path("/kaggle/input") / row["image_path"]

                    if image_path.exists():
                        try:
                            img = Image.open(image_path)
                            st.image(img, use_container_width=True)

                            # ç”»åƒæƒ…å ±ã‚’è¡¨ç¤º
                            st.markdown(f"""
                            **ID**: {row["image_path"].split("/")[-1].replace(".jpg", "")}  
                            **State**: {row["State"]}  
                            **Species**: {row["Species"]}  
                            **Date**: {row["Sampling_Date"].strftime("%Y-%m-%d")}  
                            **NDVI**: {row["Pre_GSHH_NDVI"]:.2f}  
                            **Height**: {row["Height_Ave_cm"]:.2f} cm
                            """)

                            # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå€¤ã‚’è¡¨ç¤º
                            targets = train_df[
                                train_df["image_path"] == row["image_path"]
                            ][["target_name", "target"]]
                            st.dataframe(
                                targets.set_index("target_name"),
                                use_container_width=True,
                            )
                        except Exception as e:
                            st.error(f"ç”»åƒã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ: {e}")
                    else:
                        st.warning(f"ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {image_path}")
    else:
        st.warning("ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

# ================== Correlation Analysis ==================
elif page == "ğŸ”— Correlation Analysis":
    st.header("ğŸ”— ç›¸é–¢åˆ†æ")

    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆé–“ã®ç›¸é–¢
    st.subheader("ğŸ¯ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆé–“ã®ç›¸é–¢")

    # Pivot to wide format
    target_wide = train_df.pivot_table(
        values="target", index="image_path", columns="target_name"
    )

    corr_matrix = target_wide.corr()

    fig = px.imshow(
        corr_matrix,
        labels=dict(color="Correlation"),
        title="ã‚¿ãƒ¼ã‚²ãƒƒãƒˆé–“ã®ç›¸é–¢ä¿‚æ•°",
        color_continuous_scale="RdBu_r",
        aspect="auto",
        zmin=-1,
        zmax=1,
    )
    st.plotly_chart(fig, use_container_width=True)
    st.dataframe(corr_matrix, use_container_width=True)

    # ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®ç›¸é–¢
    st.markdown("---")
    st.subheader("ğŸ“Š ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆé–“ã®ç›¸é–¢")

    # å„ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®ç›¸é–¢ã‚’è¨ˆç®—
    feature_cols = ["Pre_GSHH_NDVI", "Height_Ave_cm"]

    corr_results = []
    for target in train_df["target_name"].unique():
        target_df = train_df[train_df["target_name"] == target]
        for feature in feature_cols:
            corr = target_df[feature].corr(target_df["target"])
            corr_results.append(
                {"Target": target, "Feature": feature, "Correlation": corr}
            )

    corr_df = pd.DataFrame(corr_results)

    # Pivot for heatmap
    corr_pivot = corr_df.pivot(index="Target", columns="Feature", values="Correlation")

    fig = px.imshow(
        corr_pivot,
        labels=dict(color="Correlation"),
        title="ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆé–“ã®ç›¸é–¢ä¿‚æ•°",
        color_continuous_scale="RdBu_r",
        aspect="auto",
        zmin=-1,
        zmax=1,
    )
    st.plotly_chart(fig, use_container_width=True)
    st.dataframe(corr_pivot, use_container_width=True)

    # ãƒšã‚¢ãƒ—ãƒ­ãƒƒãƒˆçš„ãªåˆ†æ
    st.markdown("---")
    st.subheader("ğŸ“ˆ ç‰¹å¾´é‡é–“ã®é–¢ä¿‚")

    image_df = train_df.drop_duplicates(subset=["image_path"]).copy()

    # NDVI vs Height colored by state
    fig = px.scatter(
        image_df,
        x="Pre_GSHH_NDVI",
        y="Height_Ave_cm",
        color="State",
        size="Height_Ave_cm",
        title="NDVI vs é«˜ã•ï¼ˆå·åˆ¥ï¼‰",
        opacity=0.6,
    )
    st.plotly_chart(fig, use_container_width=True)

    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå€¤ã®é–¢ä¿‚æ€§
    st.markdown("---")
    st.subheader("ğŸ¯ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå€¤é–“ã®æ•£å¸ƒå›³")

    # Dry_Total vs Dry_Green
    scatter_df = target_wide.reset_index()

    fig = px.scatter(
        scatter_df,
        x="Dry_Green_g",
        y="Dry_Total_g",
        title="Dry_Green vs Dry_Total",
        opacity=0.5,
        trendline="ols",
    )
    st.plotly_chart(fig, use_container_width=True)

    # GDM vs Dry_Green
    fig = px.scatter(
        scatter_df,
        x="Dry_Green_g",
        y="GDM_g",
        title="Dry_Green vs GDM",
        opacity=0.5,
        trendline="ols",
    )
    st.plotly_chart(fig, use_container_width=True)

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.markdown(
    """
<div style='text-align: center'>
    <p>ğŸŒ± Pasture Biomass Prediction EDA | Built with Streamlit</p>
</div>
""",
    unsafe_allow_html=True,
)
